# ğŸ§  AI Document Reader

An advanced **AI-powered document understanding system** that reads, indexes, and answers questions from your documents using **large language models (LLMs)** like **Mistral-7B** and the **LangChain** framework.

---

## ğŸš€ Features

- ğŸ“„ **Multi-format Support** â€“ Reads and processes `.pdf`, `.docx`, `.pptx`, and `.txt` files.
- ğŸ§  **LLM Integration** â€“ Uses `Mistral-7B` for natural language understanding and response generation.
- âš¡ **Vector Search** â€“ Leverages FAISS/ChromaDB for efficient semantic retrieval.
- ğŸ” **Context-aware Q&A** â€“ Ask any question related to your documents.
- ğŸ’¾ **Optimized Loading** â€“ Automatically adapts between 4-bit quantization (GPU) or CPU fallback.
- ğŸ§© **LangChain Framework** â€“ Modular and extendable pipeline for document ingestion and querying.

---

## ğŸ§© Tech Stack

| Component | Technology |
|------------|-------------|
| Language Model | [Mistral-7B](https://huggingface.co/mistralai/Mistral-7B-v0.1) |
| Framework | [LangChain](https://www.langchain.com/) |
| Embeddings | `sentence-transformers` |
| Databases | `FAISS` / `ChromaDB` |
| Document Parsing | `pypdf`, `python-docx`, `python-pptx` |
| Backend Language | Python 3.10+ |
| Libraries | Transformers, Accelerate, Torch, LangChain-Community |

---

## âš™ï¸ Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/<your-username>/AI_Document_Reader.git
cd AI_Document_Reader
pip install -r requirements.txt
```

Or install directly in a Jupyter/Colab notebook:

```python
!pip install -U transformers accelerate langchain langchain-community sentence-transformers faiss-cpu chromadb pypdf python-docx python-pptx
```

---

## ğŸ§­ Usage

1. **Load the model and tokenizer**
   ```python
   tokenizer, model = load_mistral_safely("mistralai/Mistral-7B-v0.1")
   ```

2. **Ingest your document**
   ```python
   from langchain_community.document_loaders import PyPDFLoader
   docs = PyPDFLoader("sample.pdf").load()
   ```

3. **Build embeddings and store**
   ```python
   from langchain.vectorstores import FAISS
   vector_store = FAISS.from_documents(docs, embedding_function)
   ```

4. **Ask questions**
   ```python
   query = "Summarize key insights from the document"
   results = vector_store.similarity_search(query)
   ```

---

## ğŸ§  How It Works

1. **Document Loading** â€“ Reads supported files and extracts text.
2. **Chunking** â€“ Splits text into manageable segments.
3. **Embedding** â€“ Converts text into numerical vectors using `sentence-transformers`.
4. **Vector Search** â€“ Uses FAISS/ChromaDB for similarity matching.
5. **LLM Reasoning** â€“ Uses Mistral-7B to generate contextual, human-like answers.

---

## ğŸ§° Example Use Cases

- Intelligent document Q&A system
- Automated meeting summaries
- Legal or research paper analysis
- Knowledge base indexing
- Educational content understanding

---

## ğŸ“¦ Requirements

- Python â‰¥ 3.10
- At least 8GB RAM (for CPU)
- GPU recommended for faster performance (with 4-bit quantization)

---

## ğŸ§‘â€ğŸ’» Author

**Vihaan Kaushik**  
B.Tech IT, ABES Engineering College  
ğŸ“§ workvihu@gmail.com  

---

## ğŸªª License

This project is licensed under the **MIT License** â€“ feel free to use and modify with attribution.

---

## ğŸŒŸ Future Improvements

- Add web UI using Streamlit or Gradio  
- Multi-document summarization  
- Fine-tuned model integration  
- Local database caching for offline retrieval  
